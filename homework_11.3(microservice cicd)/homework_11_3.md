# Домашнее задание к занятию "11.03 Микросервисы: подходы"

Вы работаете в крупной компанию, которая строит систему на основе микросервисной архитектуры.
Вам как DevOps специалисту необходимо выдвинуть предложение по организации инфраструктуры, для разработки и эксплуатации.


## Задача 1: Обеспечить разработку

Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка. 
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- Облачная система;
- Система контроля версий Git;
- Репозиторий на каждый сервис;
- Запуск сборки по событию из системы контроля версий;
- Запуск сборки по кнопке с указанием параметров;
- Возможность привязать настройки к каждой сборке;
- Возможность создания шаблонов для различных конфигураций сборок;
- Возможность безопасного хранения секретных данных: пароли, ключи доступа;
- Несколько конфигураций для сборки из одного репозитория;
- Кастомные шаги при сборке;
- Собственные докер образы для сборки проектов;
- Возможность развернуть агентов сборки на собственных серверах;
- Возможность параллельного запуска нескольких сборок;
- Возможность параллельного запуска тестов;

Обоснуйте свой выбор.

## Задача 2: Логи

Предложите решение для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- Сбор логов в центральное хранилище со всех хостов обслуживающих систему;
- Минимальные требования к приложениям, сбор логов из stdout;
- Гарантированная доставка логов до центрального хранилища;
- Обеспечение поиска и фильтрации по записям логов;
- Обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;
- Возможность дать ссылку на сохраненный поиск по записям логов;

Обоснуйте свой выбор.

## Задача 3: Мониторинг

Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- Сбор метрик со всех хостов, обслуживающих систему;
- Сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
- Сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
- Сбор метрик, специфичных для каждого сервиса;
- Пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;
- Пользовательский интерфейс с возможность настраивать различные панели для отслеживания состояния системы;

Обоснуйте свой выбор.

## Задача 4: Логи * (необязательная)

Продолжить работу по задаче API Gateway: сервисы используемые в задаче пишут логи в stdout. 

Добавить в систему сервисы для сбора логов Vector + ElasticSearch + Kibana со всех сервисов обеспечивающих работу API.

### Результат выполнения: 

docker compose файл запустив который можно перейти по адресу http://localhost:8081 по которому доступна Kibana.
Логин в Kibana должен быть admin пароль qwerty123456


## Задача 5: Мониторинг * (необязательная)

Продолжить работу по задаче API Gateway: сервисы используемые в задаче предоставляют набор метрик в формате prometheus:

- Сервис security по адресу /metrics
- Сервис uploader по адресу /metrics
- Сервис storage (minio) по адресу /minio/v2/metrics/cluster

Добавить в систему сервисы для сбора метрик (Prometheus и Grafana) со всех сервисов обеспечивающих работу API.
Построить в Graphana dashboard показывающий распределение запросов по сервисам.

### Результат выполнения: 

docker compose файл запустив который можно перейти по адресу http://localhost:8081 по которому доступна Grafana с настроенным Dashboard.
Логин в Grafana должен быть admin пароль qwerty123456


___
## Выполнение ДЗ:

## Задача 1: Обеспечить разработку

Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка. 

Решение должно соответствовать следующим требованиям:
- Облачная система;
- Система контроля версий Git;
- Репозиторий на каждый сервис;
- Запуск сборки по событию из системы контроля версий;
- Запуск сборки по кнопке с указанием параметров;
- Возможность привязать настройки к каждой сборке;
- Возможность создания шаблонов для различных конфигураций сборок;
- Возможность безопасного хранения секретных данных: пароли, ключи доступа;
- Несколько конфигураций для сборки из одного репозитория;
- Кастомные шаги при сборке;
- Собственные докер образы для сборки проектов;
- Возможность развернуть агентов сборки на собственных серверах;
- Возможность параллельного запуска нескольких сборок;
- Возможность параллельного запуска тестов;

Предлагаю воспользоваться следующим решением:
1. Для хранения артефактов использовать `Nexus`. Он позволит взаимодействовать с большим количеством разных сборщиков (Maven, Gradle и т.д.). А также для каждой сборки использовать свой репозиторий.
2. Для непрерывной интеграции и непрерывной поставке использовать `TeamCity`. 
- Он позволяет работать и в облаке, и в докере собирать проекты и на отдельных серверах. 
- Возможность безопасного хранения паролей, ключей доступа и т.д в закрытом виде.
- Использование шаблонов для различных конфигураций сборки. (чего нет в `Jenkins` и в `GitlabCI`)
- Запуск по событиям и по кнопке при необходимости.
- Параллельные сборки и тесты и кастомные шаги при сборке.

Т.е. в целом `TeamCity` подходим нам по всем критериям для CI\CD в данном случае. А также имеет бесплатную версию с 3 агентами и 100 конфигураций сборок. При необходимости, можем добавить агентов или же попробовать воспользоваться программой поддержки OpenSource.

**P/S. По данному вопросу наиболее интересно Ваше мнение как специалиста с опытом. Какой бы Вы выбрали оркестратор для CI\CD в данном случае и почему? Очень хочется услышать комментарии с отражением на реальный кейс.**
___
## Задача 2: Логи

Решение должно соответствовать следующим требованиям:
- Сбор логов в центральное хранилище со всех хостов обслуживающих систему;
- Минимальные требования к приложениям, сбор логов из stdout;
- Гарантированная доставка логов до центрального хранилища;
- Обеспечение поиска и фильтрации по записям логов;
- Обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;
- Возможность дать ссылку на сохраненный поиск по записям логов;


Я предложу посмотреть в сторону `EFK(Elastic + Fluent Bit + Kibana)`. В данном кейсе, `Fluent Bit` заменяет `Logstash`, так как он является очень легковесным и производительным. Но ограничен немного возможностями, если нужны более широкие возможности, то вместо `Fluent Bit` можно рассмотреть `Fluentd`.

Данный стек имеет хранилище `Elasticsearch` и визуализацию данных в WEB-интефрейсе с помощью `Kibana`. А `Fluent Bit` позволит собирать данные ищ stdout приложений, парсить полученные данные с помощью модуля Parser, фильтровать с помощью модуля Filter по заданным критериям отсекая ненужное, буферовать при необходимости логи как в ОЗУ так и на диске, что гарантирует доставку в случае чего, а также отправлять сразу в `Elasticsearch`.

При необходимости, логи можно отправлять и на `Fluentd` для дополнительной обработки логов и дальнейшей отправки в `Elasticsearch`

При необходимости, из `Kibana` можно сделать запрос-ссылку для предоставления разработчику на анализ, что подходит под наши критерии.

Дополнительно, можно прикрутить `ElastAlert` для того чтобы отправлять алерты в случае обнаружения в логах определенных настроенных событий.

Также, немаловажным параметром будет - это в целом легкость развертывания и изучения данного стека для первичной работы, так как он является одним из часто применяемых стандартов и можно найти много информации по нему.
___
## Задача 3: Мониторинг

Решение должно соответствовать следующим требованиям:
- Сбор метрик со всех хостов, обслуживающих систему;
- Сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
- Сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
- Сбор метрик, специфичных для каждого сервиса;
- Пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;
- Пользовательский интерфейс с возможность настраивать различные панели для отслеживания состояния системы;

Предложу использовать `Prometheus` для мониторинга + `Grafana` для визуализации.

Основы стека составляют:
1. TSDB для хранения данных, что повышает производительносить и позволяет сжимать данные. К примеру, `Zabbix` по умолчанию использует реляционные БД, что уже будет проигрывать `Prometheus`
2. Pushgateway - кмопонент для приема данных извне, т.е. реализация push-модели. По итогу, мы можем при необходимости выбирать какую модель нам использовать.
3. Встроенный AlertManager - позволяет очень гибко настроить алерты на разные каналы.
4. Возможность подключение визуализации. В данном случае возьмём мощный визуализатор `Grafana`
5. На серверах устанавливаются агенты - `exporter`, которые собирают и хранят метрики на сервере до сбора системой мониторинга.
6. С помощью клиентских библиотек на разных языках можно внедрить выдачу метрики сразу в приложение.

По итогу, почти весь набор компонентов `Prometheus` не требует особых дополнительных настроек и работает "из коробки". При работе по методу pull-модели, то достаточно будет указать лишь узлы сервера для сбора метрик. Сейчас `Prometheus` занимает одну из лидирующих позиций, соответственно, информации по нему можно найти довольно много.